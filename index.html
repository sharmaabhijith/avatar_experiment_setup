<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="Given a video and a text prompt, Dreamix edits the video while maintaining fidelity to color, posture, object size and camera pose, resulting in a temporally consistent video.">
  <meta property="og:title" content="Dreamix: Video Diffusion Models are General Video Editors"/>
  <meta property="og:description" content="Given a video and a text prompt, Dreamix edits the video while maintaining fidelity to color, posture, object size and camera pose, resulting in a temporally consistent video."/>
  <meta property="og:url" content="https://dreamix-video-editing.github.io"/>
  <meta property="og:image" content="static/image/og_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="Dreamix: Video Diffusion Models are General Video Editors">
  <meta name="twitter:description" content="Given a video and a text prompt, Dreamix edits the video while maintaining fidelity to color, posture, object size and camera pose, resulting in a temporally consistent video.">
  <meta name="twitter:image" content="static/images/twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="Video diffusion models, video editing, dreamix, dreambooth, imagen-video">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>CART: CARLA Town 10 Dataset</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Experimental Workflow for AVATAR</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://sharmaabhijith.github.io" target="_blank">Abhijith Sharma</a><sup>*,1</sup>,
              </span>
              <span class="author-block">
                <a href="https://space.uwo.ca/people/our-members/narayan-apurva/index.html" target="_blank">Apurva Narayan</a><sup>†,2</sup>,
              </span>
              <span class="author-block">
                <a href="https://uwaterloo.ca/automation-intelligent-systems-group/profiles/nasser-lashgarian-azad" target="_blank">Nasser Azad</a><sup>†,1</sup>,
              </span>
              <span class="author-block">
                <a href="https://uwaterloo.ca/electrical-computer-engineering/profile/sfischme" target="_blank">Sebastian Fischmeister</a><sup>†,1</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/stefan-marksteiner-332a4184?originalSubdomain=at" target="_blank">Stefan Marksteiner</a><sup>3</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>University of Waterloo,</span>
              <span class="author-block"><sup>2</sup>Western University,</span>
              <span class="author-block"><sup>3</sup>AVL, Graz Austria</span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Main Author, <sup>†</sup>Indicates Equal Advising</small></span>
              <span class="eql-cntrb"><small></small></span>
            </div>
            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Paper Link -->
                <span class="link-block">
                  <a href="https://ieeexplore.ieee.org/abstract/document/10646575/" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>Original Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/sharmaabhijith/AVATAR/tree/master" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>GitHub</span>
                  </a>
                </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
</section>


<!-- Subject Driven Video Generation carousel -->
<section class="hero teaser">
  <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <center>
        <img src="static/images/avatar_block_diagram.jpg" alt="Inference Overview" class="center-image" style="transform: scale(0.75); margin-top: -85px;"/>
        </center>
        <h2 class="subtitle has-text-centered" style="transform: scale(0.9); margin-top: -45px; margin-bottom: 0;">
          <strong>AVATAR</strong> is designed to standardize the testing process for adversarial patches, a significant concern in autonomous driving scenarios. The figure illustrates the overall flow diagram of the <strong>AVATAR</strong> Framework
        </h2>
      </div>
    </div>
  </div>
</section>
<!-- End Subject Driven Video Generation carousel -->

<!-- Workflow -->
<section class="section hero is-light">
  <center>
      <h2 class="title is-3">&#127919; High-Level Overview of Workflow</h2>
  </center>
  <div class="columns is-centered">
      <ul style="list-style-type: none; margin-top: 50px;">
          <li style="margin-bottom: 10px;">🌟 <strong>STEP 1:</strong> &nbsp;&nbsp; Set up <strong>CARLA from source</strong> with <strong>Unreal Engine</strong> and install all required drivers and libraries.</li>
          <li style="margin-bottom: 10px;">🌟 <strong>STEP 2:</strong> &nbsp;&nbsp; Develop and train an <strong>object detection model</strong> for evaluation against adversarial patches <em>(target model).</em></li>
          <li style="margin-bottom: 10px;">🌟 <strong>STEP 3:</strong> &nbsp;&nbsp; Create and train <strong>adversarial patches</strong> for testing the target model within CARLA.</li>
          <li style="margin-bottom: 10px;">🌟 <strong>STEP 4:</strong> &nbsp;&nbsp; Integrate the <strong>object detection model</strong> with CARLA's PythonAPI Client for real-time simulation analysis.</li>
          <li style="margin-bottom: 10px;">🌟 <strong>STEP 5:</strong> &nbsp;&nbsp; Add <strong>adversarial patches as material assets</strong> and update vehicle blueprints in Unreal Engine to apply the patches.</li>
          <li style="margin-bottom: 10px;">🌟 <strong>STEP 6:</strong> &nbsp;&nbsp; Use <strong>AVATAR's GUI</strong> to configure experiment parameters and initiate the CARLA simulation.</li>
          <li style="margin-bottom: 10px;">🌟 <strong>STEP 7:</strong> &nbsp;&nbsp; Evaluate post-simulation results using the <strong>Adversarial Trace Classifier</strong> to detect adversarial impacts.</li>
      </ul>
  </div>
</section>
<!-- End Workflow -->


<!-- CARLA UE -->
<section class="section hero">
  <div class="hero-body">
    <div class="container is-max-desktop" style="margin-bottom: -50px;">
      <center>
          <h2 class="title is-3" style="margin-top: -50px;">&#128663; Installing CARLA from Source &#128736;</h2>
      </center>
      <center>
        <em>
        <p style="margin-bottom: 20px; margin-top: 30px">Installing CARLA from source allows full access to its underlying code and assets, 
        enabling customization of maps, vehicle models, and other resources. It provides the flexibility to modify and extend the simulator's functionality, 
        such as adding new features or adjusting existing ones, which cannot be done with pre-built versions.</p>
        </em>
      </center>
      <ul>
        <li style="margin-bottom: 10px;">&#10148; As we need to integrate adversarial patch in the CARLA map, we need to install CARLA from source.</li>
        <li style="margin-bottom: 10px;">&#10148; This process is slightly more complex as we also need to install Unreal Engine (UE), as compared to using pre-built CARLA.</li>
        <li style="margin-bottom: 10px;">&#10148; Ensure that the GPU drivers and CUDA dependencies are properly configured, ensuring compatibility with PyTorch version.</li>
        <li style="margin-bottom: 10px;">&#10148; Follow step-by-step instruction from this link <a href="https://carla.readthedocs.io/en/latest/build_linux/" target="_blank">CARLA Linux Build</a> to install Unreal Engine and CARLA.</li>
        <li style="margin-bottom: 10px;">&#10148; Eventhough we have newer versions of CARLA as well as UE, we work with stable versions: CARLA 0.9.12 and UE 4.26.</li>
        <li style="margin-bottom: 10px;">&#10148; It is essential to install CARLA's fork of UE 4.26, as it includes specific patches required for CARLA. Avoid using a random version to ensure compatibility.</li>
      </ul>
    </div>
  </div>
</section>
<!-- End CARLA UE -->


<!-- OD MODEL -->
<section class="section hero is-light">
  <div class="hero-body">
    <div class="container is-max-desktop" style="margin-bottom: -50px;">
      <center>
          <h2 class="title is-3" style="margin-top: -50px;">🤖 Training Object Detection Model </h2>
      </center>
      <center>
        <em>
        <p style="margin-bottom: 20px; margin-top: 30px">We utilize YOLO for our experiments due to its superior performance compared to R-CNNs. YOLO (You Only Look Once) offers faster inference and 
          efficiency by processing the entire image in a single pass, making it ideal for real-time applications </p>
        </em>
      </center>
      <ul>
        <li style="margin-bottom: 10px;">&#10148; AVATAR is object detection model-agnostic but requires the model's weights and architecture for its use with CARLA.</li>
        <li style="margin-bottom: 10px;">&#10148; The model's architecture is crucial for model loading for object detection using CARLA's Python API Client (see later).</li>
        <li style="margin-bottom: 10px;">&#10148; The model's weights can be imported during experiment initialization using AVATAR's GUI.</li>
        <li style="margin-bottom: 10px;">&#10148; Ensure the same technique (code) used to train or load the model is followed when integrating it into CARLA.</li>
        <li style="margin-bottom: 10px;">&#10148; YOLOv5 was used in our experiments; however, newer architectures (e.g., YOLOv11) can also be utilized.</li>
        <li style="margin-bottom: 10px;">&#10148; Refer to <a href="https://github.com/ultralytics/yolov5/" target="_blank" style="color: #007BFF;">Ultralytics GitHub</a> to load and train an object detection model of your choice.</li>
        <li style="margin-bottom: 10px;">&#10148; The dataset for model training must be photorealistic like <a href="https://sharmaabhijith.github.io/CARLA_Town10_Dataset/" target="_blank" style="color: #007BFF;">CART</a> for its effectiveness in CARLA or in the real world</li>
      </ul>
    </div>
  </div>
</section>
<!-- End OD MODEL -->


<!-- ADV PATCH -->
<section class="section hero">
  <div class="hero-body">
    <div class="container is-max-desktop" style="margin-bottom: -50px;">
      <center>
        <h2 class="title is-3" style="margin-top: -50px;">🕷️ Training Adversarial Patch </h2>
      </center>
      <center>
        <em>
        <p style="margin-bottom: -70px; margin-top: 30px">Download a pre-trained adversarial patch, crafted using the CART dataset, for attacking YOLOv5's detection of a car in the CARLA environment. We use this patch in all our experiments.</p>
        </em>
        <div >
          <img src="static/images/adversarial_patch.png" alt="adv patch" class="center-image" style="transform: scale(0.7); margin-top: 70px;"/>
        </div>
        <span class="link-block" style="margin-top: -20px;">
          <a href="https://github.com/sharmaabhijith/avatar_experiment_setup/blob/main/static/images/adversarial_patch.png?raw=true" target="_blank"
            class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
              <i class="fa fa-download"></i>
            </span>
            <span>Download Image File</span>
          </a>
        </span>
      </center>
      <ul style="margin-top: 20px;">
        <li style="margin-bottom: 10px;">&#10148; Adversarial patches can be designed as <strong>targeted</strong> (more challenging) or <strong>untargeted</strong> (simpler).</li>
        <li style="margin-bottom: 10px;">&#10148; In our experiments, the patch misled YOLOv5 to ignore cars with the patch applied (untargeted approach).</li>
        <li style="margin-bottom: 10px;">&#10148; Refer to this <a href="https://github.com/SamSamhuns/yolov5_adversarial/" target="_blank" style="color: #007BFF;">GitHub repository</a> for training adversarial patches on YOLOv5.</li>
        <li style="margin-bottom: 10px;">&#10148; The YOLOv5 model in the repository is based on Ultralytics, making it compatible with our trained models.</li>
        <li style="margin-bottom: 10px;">&#10148; Patch training hyperparameters require trial & error. (Our case: 200×200 patch, 100 epochs, learning rate 0.03).</li>
        <li style="margin-bottom: 10px;">&#10148; Use a photorealistic dataset like <a href="https://sharmaabhijith.github.io/CARLA_Town10_Dataset/" target="_blank" style="color: #007BFF;">CART</a> for effective results in CARLA or real-world scenarios.</li>
        <li style="margin-bottom: 10px;">&#10148; Traning combines <strong>classification loss</strong>, <strong>total variation</strong>, and <strong>non-printability score</strong>, applying patch randomly over each image.</li>
      </ul>      
      </div>
    </div>
  </div>
</section>
<!-- End ADV PATCH -->



<!-- OD MODEL IN CARLA -->
<section class="section hero is-light">
  <div class="hero-body">
    <div class="container is-max-desktop" style="margin-bottom: -50px;">
      <center>
          <h2 class="title is-3" style="margin-top: -50px;">📸 Object Detection in CARLA </h2>
      </center>
      <center>
        <em>
        <p style="margin-bottom: 20px; margin-top: 30px"><strong>CARLA's Python API Client</strong> is an interface that enables users to interact with simulator programmatically using Python. 
          It provides a high-level API to control various aspects of simulation, like spawning, managing or controlling actors and accessing their sensor data. This client facilitates seamless integration of custom code. Hence, the object detection must be integrated into the Python API client.
          This allows the vehicle to autonomously navigate the map while detecting objects in the scene. </p>
        </em>
        <div>
          <img src="static/images/pythonapi.png" alt="adv patch" class="center-image" style="transform: scale(0.6); margin-top: -80px;"/>
        </div>
        <div style="transform: scale(0.95); margin-top: -80px; margin-bottom: 30px;">
          <p>Source: <a href="https://carla.readthedocs.io/en/latest/build_system/" target="_blank" style="color: #007BFF;">CARLA Python API Docs</a></p>
          </em>
        </div>
 
      </center>
      <ul style="margin-top: 20px;">
        <li style="margin-bottom: 10px;">&#10148; CARLA, built from source, requires substantial GPU resources due to its dependency on Unreal Engine (GPU-intensive).</li>
        <li style="margin-bottom: 10px;">&#10148; In our experiments, the simulation runs in autopilot mode, enabling the vehicle to navigate autonomously within the map.</li>
        <li style="margin-bottom: 10px;">&#10148; Combining object detection with Python API's autopilot functionality demands a high-performance GPU (min. 16GB).</li>
        <li style="margin-bottom: 10px;">&#10148; Access the object detection integration code for Python API's autopilot mode here: <a href="https://github.com/sharmaabhijith/AVATAR/blob/master/auto_object_detection.py" target="_blank" style="color: #007BFF;">GitHub Link</a>.</li>    
      </ul>
    </div>
  </div>
</section>
<!-- End OD MODEL IN CARLA -->


<!-- PATCH IN CARLA -->
<section class="section hero">
  <div class="hero-body">
    <div class="container is-max-desktop" style="margin-bottom: -50px;">
      <center>
          <h2 class="title is-3" style="margin-top: -50px;">⚠️🚗 Adversarial Patch in CARLA </h2>
      </center>
      <center>
        <em>
        <p style="margin-bottom: 20px; margin-top: 30px">Allows evaluation of the adversarial patch's impact on object detection, while blending the patch visually with the scene for realism. 
          It enables testing autonomous driving systems in near-real-world conditions.</p>
        </em>
        <div class="columns is-centered has-text-centered" style="margin-top: 40px;">
          <div class="column is-two-fifths">
              <!-- Image embed code here -->
              <img src="static/images/materialblp.png" alt="material blp" style="transform: scale(1);"/>
          </div>
          <div class="column is-three-fifths">
            <!-- Image embed code here -->
            <img src="static/images/vehicle_blp.png" alt="vehicle blp" style="transform: scale(0.9); transform-origin: top center;"/>
          </div>
        </div>
        <div style="transform: scale(0.95); margin-top: -40px; margin-bottom: 30px;">
          <p>Material Generation and Modified Adversarial Vehicle Blueprint</p>
          </em>
        </div>
      </center>
      <ul>
        <li style="margin-bottom: 30px;">&#10148; <strong>Adversarial Patch Import into CARLA:</strong>
          <ul>
            <li>Import the adversarial patch into Unreal Engine. Convert the trained patch image (.png/.jpeg) into a CARLA asset (.uasset). The patch can be attached to a moving actor (vehicle) or placed at a static location in the map.</li>
          </ul>
        </li>
        <li style="margin-bottom: 30px;">&#10148; <strong>Material Instance Creation in Unreal Engine:</strong>
          <ul>
            <li>Create a material instance in UE. Configure properties such as <strong>opacity:</strong> controls transparency and <strong>roughness:</strong> adjusts surface texture. Use <strong>metallic material</strong> with high roughness and opacity for better visibility. Assign the trained patch's file path in UE’s blueprint library. UE reads the image and converts it into a material instance.</li>
          </ul>
        </li>
        <li style="margin-bottom: 30px;">&#10148; <strong>Applying Adversarial Patch as a CARLA Asset:</strong>
          <ul style="margin-top: 10px;">
            <li style="margin-left: 15px;">&#9654; Adversarial material instance created in UE can be applied to any CARLA asset, such as a vehicle or a static object.</li>
            <li style="margin-left: 15px;">&#9654; This integration ensures the patch appears as a natural and realistic part of the environment.</li>
            <li style="margin-left: 15px;">&#9654; Example setup: Attach the patch to a board mounted on a vehicle that moves randomly across the CARLA map.</li>
            <li style="margin-left: 15px;">&#9654; This dynamic setup allows for evaluating the impact of the patch on object detection during autonomous driving scenarios.</li>
            <li style="margin-left: 15px;">&#9654; A custom blueprint for the adversarial patch board is created in UE to enhance flexibility.</li>
            <li style="margin-left: 15px;">&#9654; The blueprint enables the selection of different patches dynamically, allowing experimentation with various designs.</li>
          </ul>
        </li>
      </ul>
      
    </div>
  </div>
</section>
<!-- End PATCH IN CARLA -->



<!-- AVATAR GUI -->
<section class="section hero is-light">
  <div class="hero-body">
    <div class="container is-max-desktop" style="margin-bottom: -50px;">
      <center>
          <h2 class="title is-3" style="margin-top: -50px;">🎛️ AVATAR's GUI </h2>
      </center>
      <center>
        <em>
        <p style="margin-bottom: 20px; margin-top: 30px">The GUI serves as the primary entry point for interacting with the AVATAR framework. It seamlessly integrates with the underlying PythonAPI, 
          automatically invoking the necessary components to execute experiments efficiently.</p>
        </em>
      </center>
      <ul style="margin-top: 20px;">
        <li style="margin-bottom: 10px;">&#10148; The features of GUI is explained in detail in the main paper. </li>
        <li style="margin-bottom: 10px;">&#10148; Access the Python (Tkinter based) code for the AVATAR's GUI here: <a href="https://github.com/sharmaabhijith/AVATAR/blob/master/gui.py" target="_blank" style="color: #007BFF;">GitHub Link</a>.</li>    
      </ul>
      <p>Typically, the PythonAPI is sufficient to interact with CARLA, eliminating the need to directly work with Unreal Engine.
        In our case, we modify CARLA assets (e.g., for adversarial patch attacks). This requires access to Unreal Engine asset 
        files to specify whether an adversarial patch attack should be conducted and to select the patch image to use.
      </p>
      <br>
      <p>
        Within the <a href="https://github.com/sharmaabhijith/AVATAR/blob/master/gui.py" target="_blank" style="color: #007BFF;">AVATAR GitHub</a> repository, 
        there is a <em>patches</em> folder. Inside, there is a flag file used to signal Unreal Engine whether an attack should be performed, and
        a patch image file is transferred to Unreal Engine, converted into an material asset, and applied to a vehicle asset.
      </p>
      <br>
      <p>
        <strong>NOTE: </strong> Do not delete the flag file, as it is critical for attack execution. 
        one can replace the patch image with a custom image to be used as adversarial patch in simulations.
      </p>
    </div>
  </div>
</section>
<!-- End AVATAR GUI -->



<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <p><em>If you find our contribution useful, please consider citing our work.</em></p>
    <pre><code>@article{sharma2024avatar,
      title={AVATAR: Autonomous Vehicle Assessment through Testing of Adversarial Patches in Real-time},
      author={Sharma, Abhijith and Narayan, Apurva and Azad, Nasser Lashgarian and Fischmeister, Sebastian and Marksteiner, Stefan},
      journal={IEEE Transactions on Intelligent Vehicles},
      year={2024},
      publisher={IEEE}
    }
</code></pre>
  </div>
</section>
<!-- End BibTex citation -->

<!--Acknowledgements -->
<section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
    We extend our gratitude to the members of the <a href="https://uwaterloo.ca/embedded-software-group/" target="_blank">Real-time Embedded Software Group</a> @UWaterloo for their invaluable insights, critical brainstorming sessions, and innovative ideas that greatly contributed to this work.
  </div>
</section>
<!--End Acknowledgements -->
  
<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->

<!-- Default Statcounter code for Dreamix
https://dreamix-video-editing.github.io -->
<script type="text/javascript">
var sc_project=12843789; 
var sc_invisible=1; 
var sc_security="e9c3bf5f"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics"
href="https://statcounter.com/" target="_blank"><img
class="statcounter"
src="https://c.statcounter.com/12843789/0/e9c3bf5f/1/"
alt="Web Analytics"
referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>

<!-- End of Statcounter Code -->

</body>
</html>
